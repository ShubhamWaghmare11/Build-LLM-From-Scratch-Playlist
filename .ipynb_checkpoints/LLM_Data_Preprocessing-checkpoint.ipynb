{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1bfed7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\",'r',encoding='utf-8') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7dc8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9d1e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, world. This, is-- a test.  ?.  test\"\n",
    "\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b19f534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'world',\n",
       " '.',\n",
       " 'This',\n",
       " ',',\n",
       " 'is',\n",
       " '--',\n",
       " 'a',\n",
       " 'test',\n",
       " '.',\n",
       " '?',\n",
       " '.',\n",
       " 'test']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in result if item.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4af3cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " '',\n",
       " ' ',\n",
       " 'world',\n",
       " '.',\n",
       " '',\n",
       " ' ',\n",
       " 'This',\n",
       " ',',\n",
       " '',\n",
       " ' ',\n",
       " 'is',\n",
       " '--',\n",
       " '',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'test',\n",
       " '.',\n",
       " '',\n",
       " ' ',\n",
       " '',\n",
       " ' ',\n",
       " '',\n",
       " '?',\n",
       " '',\n",
       " '.',\n",
       " '',\n",
       " ' ',\n",
       " '',\n",
       " ' ',\n",
       " 'test']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0610ca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a3c94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8217fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {item:integer for integer,item in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a795dc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '--',\n",
       " '.',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'Ah',\n",
       " 'Among',\n",
       " 'And',\n",
       " 'Are',\n",
       " 'Arrt',\n",
       " 'As',\n",
       " 'At',\n",
       " 'Be',\n",
       " 'Begin',\n",
       " 'Burlington',\n",
       " 'But',\n",
       " 'By',\n",
       " 'Carlo',\n",
       " 'Chicago',\n",
       " 'Claude',\n",
       " 'Come',\n",
       " 'Croft',\n",
       " 'Destroyed',\n",
       " 'Devonshire',\n",
       " 'Don',\n",
       " 'Dubarry',\n",
       " 'Emperors',\n",
       " 'Florence',\n",
       " 'For',\n",
       " 'Gallery',\n",
       " 'Gideon',\n",
       " 'Gisburn',\n",
       " 'Gisburns',\n",
       " 'Grafton',\n",
       " 'Greek',\n",
       " 'Grindle',\n",
       " 'Grindles',\n",
       " 'HAD',\n",
       " 'Had',\n",
       " 'Hang',\n",
       " 'Has',\n",
       " 'He',\n",
       " 'Her',\n",
       " 'Hermia',\n",
       " 'His',\n",
       " 'How',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'It',\n",
       " 'Jack',\n",
       " 'Jove',\n",
       " 'Just',\n",
       " 'Lord',\n",
       " 'Made',\n",
       " 'Miss',\n",
       " 'Money',\n",
       " 'Monte',\n",
       " 'Moon-dancers',\n",
       " 'Mr',\n",
       " 'Mrs',\n",
       " 'My',\n",
       " 'Never',\n",
       " 'No',\n",
       " 'Now',\n",
       " 'Nutley',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'On',\n",
       " 'Once',\n",
       " 'Only',\n",
       " 'Or',\n",
       " 'Perhaps',\n",
       " 'Poor',\n",
       " 'Professional',\n",
       " 'Renaissance',\n",
       " 'Rickham',\n",
       " 'Riviera',\n",
       " 'Rome',\n",
       " 'Russian',\n",
       " 'Sevres',\n",
       " 'She',\n",
       " 'Stroud',\n",
       " 'Strouds',\n",
       " 'Suddenly',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'They',\n",
       " 'This',\n",
       " 'Those',\n",
       " 'Though',\n",
       " 'Thwing',\n",
       " 'Thwings',\n",
       " 'To',\n",
       " 'Usually',\n",
       " 'Venetian',\n",
       " 'Victor',\n",
       " 'Was',\n",
       " 'We',\n",
       " 'Well',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Why',\n",
       " 'Yes',\n",
       " 'You',\n",
       " '_',\n",
       " 'a',\n",
       " 'abdication',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abruptly',\n",
       " 'absolute',\n",
       " 'absorbed',\n",
       " 'absurdity',\n",
       " 'academic',\n",
       " 'accuse',\n",
       " 'accustomed',\n",
       " 'across',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'added',\n",
       " 'admirers',\n",
       " 'adopted',\n",
       " 'adulation',\n",
       " 'advance',\n",
       " 'aesthetic',\n",
       " 'affect',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'again',\n",
       " 'ago',\n",
       " 'ah',\n",
       " 'air',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazement',\n",
       " 'amid',\n",
       " 'among',\n",
       " 'amplest',\n",
       " 'amusing',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'anywhere',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appointed',\n",
       " 'are',\n",
       " 'arm',\n",
       " 'arm-chair',\n",
       " 'arm-chairs',\n",
       " 'arms',\n",
       " 'art',\n",
       " 'articles',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'asked',\n",
       " 'at',\n",
       " 'atmosphere',\n",
       " 'atom',\n",
       " 'attack',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'audacities',\n",
       " 'away',\n",
       " 'awful',\n",
       " 'axioms',\n",
       " 'azaleas',\n",
       " 'back',\n",
       " 'background',\n",
       " 'balance',\n",
       " 'balancing',\n",
       " 'balustraded',\n",
       " 'basking',\n",
       " 'bath-rooms',\n",
       " 'be',\n",
       " 'beaming',\n",
       " 'bean-stalk',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'because',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begun',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'beneath',\n",
       " 'bespoke',\n",
       " 'better',\n",
       " 'between',\n",
       " 'big',\n",
       " 'bits',\n",
       " 'bitterness',\n",
       " 'blocked',\n",
       " 'born',\n",
       " 'borne',\n",
       " 'boudoir',\n",
       " 'bravura',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'breathing',\n",
       " 'bric-a-brac',\n",
       " 'briefly',\n",
       " 'brings',\n",
       " 'bronzes',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brush',\n",
       " 'bull',\n",
       " 'business',\n",
       " 'but',\n",
       " 'buying',\n",
       " 'by',\n",
       " 'called',\n",
       " 'came',\n",
       " 'can',\n",
       " 'canvas',\n",
       " 'canvases',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'career',\n",
       " 'caught',\n",
       " 'central',\n",
       " 'chair',\n",
       " 'chap',\n",
       " 'characteristic',\n",
       " 'charming',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'cheeks',\n",
       " 'chest',\n",
       " 'chimney-piece',\n",
       " 'chucked',\n",
       " 'cigar',\n",
       " 'cigarette',\n",
       " 'cigars',\n",
       " 'circulation',\n",
       " 'circumstance',\n",
       " 'circus-clown',\n",
       " 'claimed',\n",
       " 'clasping',\n",
       " 'clear',\n",
       " 'cleverer',\n",
       " 'close',\n",
       " 'clue',\n",
       " 'coat',\n",
       " 'collapsed',\n",
       " 'colour',\n",
       " 'come',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'companion',\n",
       " 'compared',\n",
       " 'complex',\n",
       " 'confident',\n",
       " 'congesting',\n",
       " 'conjugal',\n",
       " 'constraint',\n",
       " 'consummate',\n",
       " 'contended',\n",
       " 'continued',\n",
       " 'corner',\n",
       " 'corrected',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'count',\n",
       " 'countenance',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'covered',\n",
       " 'craft',\n",
       " 'cried',\n",
       " 'crossed',\n",
       " 'crowned',\n",
       " 'crumbled',\n",
       " 'cry',\n",
       " 'cured',\n",
       " 'curiosity',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'curtains',\n",
       " 'd',\n",
       " 'dabble',\n",
       " 'damask',\n",
       " 'dark',\n",
       " 'dashed',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'deadening',\n",
       " 'dear',\n",
       " 'deep',\n",
       " 'deerhound',\n",
       " 'degree',\n",
       " 'delicate',\n",
       " 'demand',\n",
       " 'denied',\n",
       " 'deploring',\n",
       " 'deprecating',\n",
       " 'deprecatingly',\n",
       " 'desire',\n",
       " 'destroyed',\n",
       " 'destruction',\n",
       " 'desultory',\n",
       " 'detail',\n",
       " 'diagnosis',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'died',\n",
       " 'dim',\n",
       " 'dimmest',\n",
       " 'dingy',\n",
       " 'dining-room',\n",
       " 'disarming',\n",
       " 'discovery',\n",
       " 'discrimination',\n",
       " 'discussion',\n",
       " 'disdain',\n",
       " 'disdained',\n",
       " 'disease',\n",
       " 'disguised',\n",
       " 'display',\n",
       " 'dissatisfied',\n",
       " 'distinguished',\n",
       " 'distract',\n",
       " 'divert',\n",
       " 'do',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'domestic',\n",
       " 'don',\n",
       " 'done',\n",
       " 'donkey',\n",
       " 'down',\n",
       " 'dozen',\n",
       " 'dragged',\n",
       " 'drawing-room',\n",
       " 'drawing-rooms',\n",
       " 'drawn',\n",
       " 'dress-closets',\n",
       " 'drew',\n",
       " 'dropped',\n",
       " 'each',\n",
       " 'earth',\n",
       " 'ease',\n",
       " 'easel',\n",
       " 'easy',\n",
       " 'echoed',\n",
       " 'economy',\n",
       " 'effect',\n",
       " 'effects',\n",
       " 'efforts',\n",
       " 'egregious',\n",
       " 'eighteenth-century',\n",
       " 'elbow',\n",
       " 'elegant',\n",
       " 'else',\n",
       " 'embarrassed',\n",
       " 'enabled',\n",
       " 'end',\n",
       " 'endless',\n",
       " 'enjoy',\n",
       " 'enlightenment',\n",
       " 'enough',\n",
       " 'ensuing',\n",
       " 'equally',\n",
       " 'equanimity',\n",
       " 'escape',\n",
       " 'established',\n",
       " 'etching',\n",
       " 'even',\n",
       " 'event',\n",
       " 'ever',\n",
       " 'everlasting',\n",
       " 'every',\n",
       " 'exasperated',\n",
       " 'except',\n",
       " 'excuse',\n",
       " 'excusing',\n",
       " 'existed',\n",
       " 'expected',\n",
       " 'exquisite',\n",
       " 'exquisitely',\n",
       " 'extenuation',\n",
       " 'exterminating',\n",
       " 'extracting',\n",
       " 'eye',\n",
       " 'eyebrows',\n",
       " 'eyes',\n",
       " 'face',\n",
       " 'faces',\n",
       " 'fact',\n",
       " 'faded',\n",
       " 'failed',\n",
       " 'failure',\n",
       " 'fair',\n",
       " 'faith',\n",
       " 'false',\n",
       " 'familiar',\n",
       " 'famille-verte',\n",
       " 'fancy',\n",
       " 'fashionable',\n",
       " 'fate',\n",
       " 'feather',\n",
       " 'feet',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'few',\n",
       " 'fewer',\n",
       " 'finality',\n",
       " 'find',\n",
       " 'fingers',\n",
       " 'first',\n",
       " 'fit',\n",
       " 'fitting',\n",
       " 'five',\n",
       " 'flash',\n",
       " 'flashed',\n",
       " 'florid',\n",
       " 'flowers',\n",
       " 'fluently',\n",
       " 'flung',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'fond',\n",
       " 'footstep',\n",
       " 'for',\n",
       " 'forced',\n",
       " 'forcing',\n",
       " 'forehead',\n",
       " 'foreign',\n",
       " 'foreseen',\n",
       " 'forgive',\n",
       " 'forgotten',\n",
       " 'form',\n",
       " 'formed',\n",
       " 'forming',\n",
       " 'forward',\n",
       " 'fostered',\n",
       " 'found',\n",
       " 'foundations',\n",
       " 'fragment',\n",
       " 'fragments',\n",
       " 'frame',\n",
       " 'frames',\n",
       " 'frequently',\n",
       " 'friend',\n",
       " 'from',\n",
       " 'full',\n",
       " 'fullest',\n",
       " 'furiously',\n",
       " 'furrowed',\n",
       " 'garlanded',\n",
       " 'garlands',\n",
       " 'gave',\n",
       " 'genial',\n",
       " 'genius',\n",
       " 'gesture',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'give',\n",
       " 'given',\n",
       " 'glad',\n",
       " 'glanced',\n",
       " 'glimpse',\n",
       " 'gloried',\n",
       " 'glory',\n",
       " 'go',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'good-breeding',\n",
       " 'good-humoured',\n",
       " 'got',\n",
       " 'grace',\n",
       " 'gradually',\n",
       " 'gray',\n",
       " 'grayish',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greatness',\n",
       " 'grew',\n",
       " 'groping',\n",
       " 'growing',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'half-light',\n",
       " 'half-mechanically',\n",
       " 'hall',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'handsome',\n",
       " 'hanging',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'hard',\n",
       " 'hardly',\n",
       " 'has',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'height',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hermit',\n",
       " 'herself',\n",
       " 'hesitations',\n",
       " 'hide',\n",
       " 'high',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'hint',\n",
       " 'his',\n",
       " 'history',\n",
       " 'holding',\n",
       " 'home',\n",
       " 'honour',\n",
       " 'hooded',\n",
       " 'hostess',\n",
       " 'hot-house',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'how',\n",
       " 'hung',\n",
       " 'husband',\n",
       " 'idea',\n",
       " 'idle',\n",
       " 'idling',\n",
       " 'if',\n",
       " 'immediately',\n",
       " 'in',\n",
       " 'incense',\n",
       " 'indifferent',\n",
       " 'inevitable',\n",
       " 'inevitably',\n",
       " 'inflexible',\n",
       " 'insensible',\n",
       " 'insignificant',\n",
       " 'instinctively',\n",
       " 'instructive',\n",
       " 'interesting',\n",
       " 'into',\n",
       " 'ironic',\n",
       " 'irony',\n",
       " 'irrelevance',\n",
       " 'irrevocable',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'jardiniere',\n",
       " 'jealousy',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'kind',\n",
       " 'knees',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'known',\n",
       " 'laid',\n",
       " 'lair',\n",
       " 'landing',\n",
       " 'language',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'laugh',\n",
       " 'laughed',\n",
       " 'lay',\n",
       " 'leading',\n",
       " 'lean',\n",
       " 'learned',\n",
       " 'least',\n",
       " 'leathery',\n",
       " 'leave',\n",
       " 'led',\n",
       " 'left',\n",
       " 'leisure',\n",
       " 'lends',\n",
       " 'lent',\n",
       " 'let',\n",
       " 'lies',\n",
       " 'life',\n",
       " 'life-likeness',\n",
       " 'lift',\n",
       " 'lifted',\n",
       " 'light',\n",
       " 'lightly',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'lingered',\n",
       " 'lips',\n",
       " 'lit',\n",
       " 'little',\n",
       " 'live',\n",
       " 'll',\n",
       " 'loathing',\n",
       " 'long',\n",
       " 'longed',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'looking',\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'lounging',\n",
       " 'lovely',\n",
       " 'lucky',\n",
       " 'lump',\n",
       " 'luncheon-table',\n",
       " 'luxury',\n",
       " 'lying',\n",
       " 'made',\n",
       " 'make',\n",
       " 'man',\n",
       " 'manage',\n",
       " 'managed',\n",
       " 'mantel-piece',\n",
       " 'marble',\n",
       " 'married',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meant',\n",
       " 'mediocrity',\n",
       " 'medium',\n",
       " 'mentioned',\n",
       " 'mere',\n",
       " 'merely',\n",
       " 'met',\n",
       " 'might',\n",
       " 'mighty',\n",
       " 'millionaire',\n",
       " 'mine',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'mirrors',\n",
       " 'modest',\n",
       " 'modesty',\n",
       " 'moment',\n",
       " 'money',\n",
       " 'monumental',\n",
       " 'mood',\n",
       " 'morbidly',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mourn',\n",
       " 'mourned',\n",
       " 'moustache',\n",
       " 'moved',\n",
       " 'much',\n",
       " 'muddling',\n",
       " 'multiplied',\n",
       " 'murmur',\n",
       " 'muscles',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'mysterious',\n",
       " 'naive',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'negatived',\n",
       " 'nervous',\n",
       " 'nervousness',\n",
       " 'neutral',\n",
       " 'never',\n",
       " 'next',\n",
       " 'no',\n",
       " 'none',\n",
       " 'not',\n",
       " 'note',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nymphs',\n",
       " 'oak',\n",
       " 'obituary',\n",
       " 'object',\n",
       " 'objects',\n",
       " 'occurred',\n",
       " 'oddly',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'open',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outline',\n",
       " 'oval',\n",
       " 'over',\n",
       " 'own',\n",
       " 'packed',\n",
       " 'paid',\n",
       " 'paint',\n",
       " 'painted',\n",
       " 'painter',\n",
       " 'painting',\n",
       " 'pale',\n",
       " 'paled',\n",
       " 'palm-trees',\n",
       " 'panel',\n",
       " 'panelling',\n",
       " 'pardonable',\n",
       " 'pardoned',\n",
       " 'part',\n",
       " 'passages',\n",
       " 'passing',\n",
       " 'past',\n",
       " 'pastels',\n",
       " 'pathos',\n",
       " 'patient',\n",
       " 'people',\n",
       " 'perceptible',\n",
       " 'perfect',\n",
       " 'persistence',\n",
       " 'persuasively',\n",
       " 'phrase',\n",
       " 'picture',\n",
       " 'pictures',\n",
       " 'pines',\n",
       " 'pink',\n",
       " 'place',\n",
       " 'placed',\n",
       " 'plain',\n",
       " 'platitudes',\n",
       " 'pleased',\n",
       " 'pockets',\n",
       " 'point',\n",
       " 'poised',\n",
       " 'poor',\n",
       " 'portrait',\n",
       " 'posing',\n",
       " 'possessed',\n",
       " 'poverty',\n",
       " 'predicted',\n",
       " 'preliminary',\n",
       " 'presenting',\n",
       " 'prestidigitation',\n",
       " 'pretty',\n",
       " 'previous',\n",
       " 'price',\n",
       " 'pride',\n",
       " 'princely',\n",
       " 'prism',\n",
       " 'problem',\n",
       " 'proclaiming',\n",
       " 'prodigious',\n",
       " 'profusion',\n",
       " 'protest',\n",
       " 'prove',\n",
       " 'public',\n",
       " 'purblind',\n",
       " 'purely',\n",
       " 'pushed',\n",
       " 'put',\n",
       " 'qualities',\n",
       " 'quality',\n",
       " 'queerly',\n",
       " 'question',\n",
       " 'quickly',\n",
       " 'quietly',\n",
       " 'quite',\n",
       " 'quote',\n",
       " 'rain',\n",
       " 'raised',\n",
       " 'random',\n",
       " 'rather',\n",
       " 're',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reared',\n",
       " 'reason',\n",
       " 'reassurance',\n",
       " 'recovering',\n",
       " 'recreated',\n",
       " 'reflected',\n",
       " 'reflection',\n",
       " 'regrets',\n",
       " 'relatively',\n",
       " 'remained',\n",
       " 'remember',\n",
       " 'reminded',\n",
       " 'repeating',\n",
       " 'represented',\n",
       " 'reproduction',\n",
       " 'resented',\n",
       " 'resolve',\n",
       " 'resources',\n",
       " 'rest',\n",
       " 'rich',\n",
       " 'ridiculous',\n",
       " 'robbed',\n",
       " 'romantic',\n",
       " 'room',\n",
       " 'rose',\n",
       " 'rs',\n",
       " 'rule',\n",
       " 'run',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'satisfaction',\n",
       " 'savour',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'scorn',\n",
       " 'scornful',\n",
       " 'secret',\n",
       " 'see',\n",
       " 'seemed',\n",
       " 'seen',\n",
       " 'self-confident',\n",
       " 'send',\n",
       " 'sensation',\n",
       " 'sensitive',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'set',\n",
       " 'sex',\n",
       " 'shade',\n",
       " 'shaking',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'shirked',\n",
       " 'short',\n",
       " 'should',\n",
       " 'shoulder',\n",
       " 'shoulders',\n",
       " 'show',\n",
       " 'showed',\n",
       " 'showy',\n",
       " 'shrug',\n",
       " 'shrugged',\n",
       " 'sight',\n",
       " 'sign',\n",
       " 'silent',\n",
       " 'silver',\n",
       " 'similar',\n",
       " 'simpleton',\n",
       " 'simplifications',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'single',\n",
       " 'sitter',\n",
       " 'sitters',\n",
       " 'sketch',\n",
       " 'skill',\n",
       " 'slight',\n",
       " 'slightly',\n",
       " 'slowly',\n",
       " 'small',\n",
       " 'smile',\n",
       " 'smiling',\n",
       " 'sneer',\n",
       " 'so',\n",
       " 'solace',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'something',\n",
       " 'spacious',\n",
       " 'spaniel',\n",
       " 'speaking-tubes',\n",
       " 'speculations',\n",
       " 'spite',\n",
       " 'splash',\n",
       " 'square',\n",
       " 'stairs',\n",
       " 'stammer',\n",
       " 'stand',\n",
       " 'standing',\n",
       " 'started',\n",
       " 'stay',\n",
       " 'still',\n",
       " 'stocked',\n",
       " 'stood',\n",
       " 'stopped',\n",
       " 'stopping',\n",
       " 'straddling',\n",
       " 'straight',\n",
       " 'strain',\n",
       " 'straining',\n",
       " 'strange',\n",
       " 'straw',\n",
       " 'stream',\n",
       " 'stroke',\n",
       " 'strokes',\n",
       " 'strolled',\n",
       " 'strongest',\n",
       " 'strongly',\n",
       " 'struck',\n",
       " 'studio',\n",
       " 'stuff',\n",
       " 'subject',\n",
       " 'substantial',\n",
       " 'suburban',\n",
       " 'such',\n",
       " 'suddenly',\n",
       " 'suffered',\n",
       " 'sugar',\n",
       " 'suggested',\n",
       " 'sunburn',\n",
       " 'sunburnt',\n",
       " 'sunlit',\n",
       " 'superb',\n",
       " 'sure',\n",
       " 'surest',\n",
       " 'surface',\n",
       " 'surprise',\n",
       " 'surprised',\n",
       " 'surrounded',\n",
       " 'suspected',\n",
       " 'sweetly',\n",
       " 'sweetness',\n",
       " 'swelling',\n",
       " 'swept',\n",
       " 'swum',\n",
       " 't',\n",
       " 'table',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'talking',\n",
       " 'tea',\n",
       " 'tears',\n",
       " 'technicalities',\n",
       " 'technique',\n",
       " 'tell',\n",
       " 'tells',\n",
       " 'tempting',\n",
       " 'terra-cotta',\n",
       " 'terrace',\n",
       " 'terraces',\n",
       " 'terribly',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'therefore',\n",
       " 'they',\n",
       " 'thin',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'this',\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ccf6c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "        \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        \n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] if s in self.str_to_int else self.str_to_int['<|unk|>'] for s in preprocessed ]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70778f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09989fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(\"HEllo i am testing this\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2941533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "705c5d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f317104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9af4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sublit terraces of the palace\"\n",
    "\n",
    "text = \"<|endoftext|>\".join((text1,text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "661d4cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|unk|> the <|unk|> terraces of the <|unk|>'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4216387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Byte pair Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99bf6945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "43275b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b511525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocab size for gpt2 is 50257\n",
      "The vocab size for gpt3 is 50281\n",
      "The vocab size for gpt4 is 100277\n"
     ]
    }
   ],
   "source": [
    "encodings = {\n",
    "    \"gpt2\":tiktoken.get_encoding(\"gpt2\"),\n",
    "    \"gpt3\":tiktoken.get_encoding(\"p50k_base\"),\n",
    "    \"gpt4\":tiktoken.get_encoding(\"cl100k_base\"),\n",
    "    \n",
    "}\n",
    "\n",
    "vocab_size = {model: encoding.n_vocab for model,encoding in encodings.items()}\n",
    "\n",
    "for model, size in vocab_size.items():\n",
    "    print(f\"The vocab size for {model} is {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2a6d5f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': 50257, 'gpt3': 50281, 'gpt4': 100277}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "431f7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        \n",
    "        for i in range(0,len(token_ids)-max_length, stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            output_chunk = token_ids[i+1:i+1+max_length]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(output_chunk))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx],self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1f6f3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GPTDatasetV1(raw_text,tokenizer,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b7a880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,batch_size=8,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0226f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128,shuffle=True,drop_last=True):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "39e2f403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fb428390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6dc74070",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2,3,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fa8c33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=6\n",
    "output_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e459e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding\n",
    "from torch import nn\n",
    "\n",
    "embedding = nn.Embedding(vocab_size,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "52665446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5971, -1.3160, -0.6500],\n",
       "        [ 0.0946, -1.0633,  0.3112],\n",
       "        [ 0.4493,  0.0504,  0.3773],\n",
       "        [-1.4798,  1.3728, -0.2862]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "89eee754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1bd86ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = nn.Embedding(vocab_size,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ea78e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f2a32a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "87e7da52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7505, -1.6099, -0.7765,  0.2307, -0.1435, -0.5554, -1.0015, -0.5450,\n",
       "          0.6731,  0.6811, -0.0442, -1.4914, -0.8475,  1.4379,  1.2102, -1.0405,\n",
       "         -0.8321, -0.9186, -0.8992,  0.6360, -0.2776,  0.3994,  0.9825, -1.2509,\n",
       "         -0.2250, -0.9712,  1.2332,  0.5613, -1.1850, -2.5315, -0.4711, -0.4844,\n",
       "         -1.8478,  0.2917,  0.5772, -2.1218, -0.9251,  1.5011,  1.5563,  0.2824,\n",
       "         -1.2502, -1.2802,  0.5946,  0.8912, -0.2161, -0.9418, -0.8641,  1.5533,\n",
       "          0.1477, -0.3288, -0.5943, -1.1993,  1.3745,  0.4937,  0.0174, -1.0196,\n",
       "         -0.2864,  0.2731,  1.2032, -0.7857, -0.0281, -1.7425, -1.5720, -1.2515,\n",
       "         -0.8142, -0.5544, -0.4541, -0.6415, -0.2308, -0.5757, -1.0518,  0.0204,\n",
       "          0.1586, -0.8134,  1.7683, -0.4985,  1.4663, -0.3481, -1.1835, -0.0375,\n",
       "         -1.1134, -0.4078, -0.2613, -0.9268,  0.0762, -1.1953, -0.0822, -0.0502,\n",
       "         -0.4343, -0.0745,  0.4503,  0.3620,  1.5415, -0.2774,  0.2013,  0.9301,\n",
       "          0.7097, -0.1409,  0.6521,  0.3603,  0.0600,  0.1333, -1.3396, -2.2604,\n",
       "         -1.3338, -1.5189,  0.7444,  2.0001,  0.4507, -1.8538, -0.6858,  0.7371,\n",
       "         -0.2400, -1.3768,  0.5422,  0.2017,  0.0787, -0.0766,  0.4585,  0.5796,\n",
       "         -1.4911,  0.3488, -0.5529,  1.0643,  2.6519, -0.2395, -1.7755,  0.3603,\n",
       "          0.4336, -0.5496, -0.1409,  0.2076, -0.4371, -2.4394,  0.3580,  1.0281,\n",
       "          0.0888, -1.9747, -0.1409,  0.9854, -0.1395, -0.2033, -1.2623,  1.0197,\n",
       "          1.3208, -2.4744,  1.5130, -0.4512,  0.3490, -0.4056,  0.2067,  0.4359,\n",
       "          0.0753,  1.2237,  0.7394,  0.0801,  0.4497,  0.4104, -0.0282,  1.0748,\n",
       "          2.6888,  0.6108, -1.5243,  2.3772,  0.1243,  0.6883,  0.0449,  1.9681,\n",
       "          0.7538, -2.0471, -1.2856,  1.1650,  0.2204,  3.2447,  1.8249,  0.0237,\n",
       "          0.5519, -0.4312,  1.4062,  0.4012,  2.0467,  0.7282, -0.5343, -1.2979,\n",
       "         -0.3266, -0.2086, -1.7739, -1.0519, -0.6214,  0.6389,  1.3884,  3.2146,\n",
       "         -0.7275, -1.2638,  1.0887, -0.2354, -0.1882, -0.4343, -0.7351,  0.3180,\n",
       "         -0.8129,  0.3722, -0.4459, -0.4198,  1.1492,  0.1017,  1.2539,  0.4994,\n",
       "          1.1591, -0.7818, -1.5447,  0.0444,  0.5271, -0.7890,  0.2150,  0.6204,\n",
       "         -0.5386,  0.4583,  0.2568,  1.6431,  1.7430,  1.0296, -0.2482,  1.2376,\n",
       "          1.2718,  0.2047, -1.3390,  0.1347, -0.4783,  1.8873, -0.5995,  1.2838,\n",
       "          1.2877,  0.2802,  0.7970, -0.2248, -0.9349,  0.2080,  0.6200,  0.2687,\n",
       "          2.1680, -0.2548,  0.7983, -0.7403, -0.6358,  1.0175, -0.4514, -1.2919,\n",
       "         -0.3985,  0.1972,  1.0305, -0.6062,  0.3794,  0.7867, -0.4399,  1.4129]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "token_embedding_layer(torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2ab8c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length =4\n",
    "\n",
    "pos_embedding_layer = nn.Embedding(max_length,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9818b0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.0292,  0.5787,  1.4943,  ..., -0.0344,  0.5735, -0.1048],\n",
       "        [ 0.8385,  0.5713, -1.9317,  ..., -1.1964, -0.6756, -1.4118],\n",
       "        [ 0.8971,  0.6961,  0.6476,  ...,  2.4527,  0.7715, -0.4936],\n",
       "        [ 1.1229, -0.6806, -0.5861,  ..., -0.8031, -0.1561, -1.6713]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb15676d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
